{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shwet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install nltk\n",
    "import tweepy as tw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br>STEP 1 - Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Twitter API credentials which are stored in a csv file\n",
    "twitter_creds = pd.read_csv(\"Twitter Creds.csv\", index_col=0)\n",
    "\n",
    "access_token = twitter_creds.loc[\"ACCESS_TOKEN\"][0]\n",
    "access_secret = twitter_creds.loc[\"ACCESS_SECRET\"][0]\n",
    "consumer_key = twitter_creds.loc[\"CONSUMER_KEY\"][0]\n",
    "consumer_secret = twitter_creds.loc[\"CONSUMER_SECRET\"][0]\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tw.API(auth)\n",
    "\n",
    "# New dataframe to store the tweets and username \n",
    "df = pd.DataFrame(columns = ['Tweets', 'User'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br>STEP 2 - Apache Spark Streaming Application on Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for spark  stream to collect the data\n",
    "def stream(data, file_name):\n",
    "    i = 0\n",
    "    for tweet in tw.Cursor(api.search, q=data, count=1000, lang='en').items():\n",
    "        print(i+1, end='\\r')\n",
    "        df.loc[i, 'Tweets'] = tweet.text\n",
    "        df.loc[i, 'User'] = tweet.user.name\n",
    "        df.to_excel('{}.xlsx'.format(file_name))\n",
    "        i+=1\n",
    "        if i == 1000:\n",
    "            break\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\r"
     ]
    }
   ],
   "source": [
    "stream(data = ['#hospital'], file_name = 'my_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove @tags and URL(s) in the tweets\n",
    "def clean_tweet(tweet):\n",
    "    return ' '.join(re.sub('(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)', ' ', tweet).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>User</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#People who believe that #FakePresident #Donal...</td>\n",
       "      <td>üè≥Ô∏è‚Äçüåàüë¨üè≥Ô∏è‚Äçüåà Dark_Marc üè≥Ô∏è‚Äçüåàü¶Ñüè≥Ô∏è‚Äçüåà</td>\n",
       "      <td>people who believe that fakepresident donaldtr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @kelly_archives: #WiC #cardiotwitter Welcom...</td>\n",
       "      <td>CareMo</td>\n",
       "      <td>rt archives wic cardiotwitter welcome doctors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @kelly_archives: Enhancing Patient Experien...</td>\n",
       "      <td>CareMo</td>\n",
       "      <td>rt archives enhancing patient experience docto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We were appointed as cost managers at the publ...</td>\n",
       "      <td>Turner &amp; Townsend</td>\n",
       "      <td>we were appointed as cost managers at the publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sad effect of #Covid19: as #Coronavirus cases ...</td>\n",
       "      <td>Naomi Fried</td>\n",
       "      <td>sad effect of covid19 as coronavirus cases ris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  #People who believe that #FakePresident #Donal...   \n",
       "1  RT @kelly_archives: #WiC #cardiotwitter Welcom...   \n",
       "2  RT @kelly_archives: Enhancing Patient Experien...   \n",
       "3  We were appointed as cost managers at the publ...   \n",
       "4  Sad effect of #Covid19: as #Coronavirus cases ...   \n",
       "\n",
       "                            User  \\\n",
       "0  üè≥Ô∏è‚Äçüåàüë¨üè≥Ô∏è‚Äçüåà Dark_Marc üè≥Ô∏è‚Äçüåàü¶Ñüè≥Ô∏è‚Äçüåà   \n",
       "1                         CareMo   \n",
       "2                         CareMo   \n",
       "3              Turner & Townsend   \n",
       "4                    Naomi Fried   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  people who believe that fakepresident donaldtr...  \n",
       "1  rt archives wic cardiotwitter welcome doctors ...  \n",
       "2  rt archives enhancing patient experience docto...  \n",
       "3  we were appointed as cost managers at the publ...  \n",
       "4  sad effect of covid19 as coronavirus cases ris...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing cleaned tweets in a new column in the Data Frame\n",
    "df['clean_tweet'] = df['Tweets'].apply(lambda x: clean_tweet(x))\n",
    "df['clean_tweet'] = df['clean_tweet'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br>STEP 3 - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the negative-words text file\n",
    "with open(\"negative-words.txt\",\"r\") as file:\n",
    "        neg_list = file.readlines()\n",
    "\n",
    "negative_words=[]\n",
    "\n",
    "for i in range(len(neg_list)):\n",
    "    negative_words.append(neg_list[i].split(\"\\n\")[0])\n",
    "    \n",
    "\n",
    "# Reading the positive-words text  file\n",
    "with open(\"positive-words.txt\",\"r\") as file:\n",
    "        pos_list = file.readlines()\n",
    "\n",
    "positive_words=[]\n",
    "\n",
    "for i in range(len(pos_list)):\n",
    "    positive_words.append(pos_list[i].split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the sentiment score for a single tweet\n",
    "def tweet_sentiment_value(tweet):\n",
    "\n",
    "    # Initializing Sentiment value to zero\n",
    "    sentiment_value=0\n",
    "    \n",
    "    # Using  nltk.toeknize to split the tweet into individual words\n",
    "    for word in nltk.word_tokenize(tweet):\n",
    "        \n",
    "        # If word is in positive list increment sentiment value by 1\n",
    "        if word in positive_words:\n",
    "            sentiment_value+=1\n",
    "        \n",
    "        # If word is in Negative list decrease sentiment value by 1\n",
    "        elif word in negative_words:\n",
    "            sentiment_value-=1\n",
    "    \n",
    "    # Return the final sentiment score of the tweet\n",
    "    return sentiment_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br><br><center>Sentiment Analysis with SPARK dataframe</center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required packages and initiating a spark session\n",
    "import findspark\n",
    "import pyspark\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import desc\n",
    "from collections import namedtuple\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init('C:\\Spark\\spark-3.0.1-bin-hadoop2.7')\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a spark Dataframe\n",
    "dfspark = spark.createDataFrame(df)\n",
    "dfspark = dfspark.dropna()\n",
    "dfspark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|              Tweets|                User|         clean_tweet|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|#People who belie...|üè≥Ô∏è‚Äçüåàüë¨üè≥Ô∏è‚Äçüåà Da...|people who believ...|\n",
      "|RT @kelly_archive...|              CareMo|rt archives wic c...|\n",
      "|RT @kelly_archive...|              CareMo|rt archives enhan...|\n",
      "|We were appointed...|   Turner & Townsend|we were appointed...|\n",
      "|Sad effect of #Co...|         Naomi Fried|sad effect of cov...|\n",
      "|Best Warrior Comp...|Martin Army Commu...|best warrior comp...|\n",
      "|Enhancing Patient...|      Kelly Anderson|enhancing patient...|\n",
      "|Two dead, a third...|   Saskia Steinhorst|two dead a third ...|\n",
      "|#WiC #cardiotwitt...|      Kelly Anderson|wic cardiotwitter...|\n",
      "|Under the rule, h...|      Orbit Products|under the rule ho...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Displaying first 10 rows of  Spark DataFrame\n",
    "dfspark.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_content</th>\n",
       "      <th>Sentiment score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#People who believe that #FakePresident #Donal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @kelly_archives: #WiC #cardiotwitter Welcom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @kelly_archives: Enhancing Patient Experien...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We were appointed as cost managers at the publ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sad effect of #Covid19: as #Coronavirus cases ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Tweet_content  Sentiment score\n",
       "0  #People who believe that #FakePresident #Donal...                0\n",
       "1  RT @kelly_archives: #WiC #cardiotwitter Welcom...                1\n",
       "2  RT @kelly_archives: Enhancing Patient Experien...                1\n",
       "3  We were appointed as cost managers at the publ...                0\n",
       "4  Sad effect of #Covid19: as #Coronavirus cases ...                0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List to score sentiment value of each tweet\n",
    "sentiment_score = []\n",
    "\n",
    "# Iterating \"clean_tweet\" column of Spark dataframe and passing each tweet thorugh \"tweet_sentiment_value\" function\n",
    "for tweets in dfspark.select('clean_tweet').collect():\n",
    "    #Storing the sentiment score in \"sentiment_score\" list \n",
    "    sentiment_score.append(tweet_sentiment_value(tweets[0]))\n",
    "    \n",
    "# Creating a  dataframe with original tweets and their corresponding sentiment score\n",
    "df2 = pd.DataFrame({\"Tweet_content\":list(df[\"Tweets\"]) , \"Sentiment score\":sentiment_score})\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <br>Step 4 - Exporting the sentiment scores to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"Final Output.csv\",  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
